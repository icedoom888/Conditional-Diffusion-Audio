training:
  output_dir: results/Phoneme2Wav
  data_root: data/processed_LJSpeech
  dataset_name: SlidingWindow
  sr: 22050
  wandb_project: natural_voices
  wandb_log_every: 100
  train_batch_size: 20
  eval_batch_size: 4
  num_epochs: 2500
  save_images_epochs: 10
  save_model_epochs: 50
  gradient_accumulation_steps: 2
  learning_rate: 1.e-4
  lr_scheduler: constant
  lr_warmup_steps: 500
  adam_beta1: 0.95
  adam_beta2: 0.999
  adam_epsilon: 1.e-8
  CFG_mask_proba: 0.1
  adam_weight_decay: 1.e-6
  use_ema: true
  ema_inv_gamma: 1
  ema_power: 0.75
  ema_max_decay: 0.999
  mixed_precision: "fp16"
  start_epoch: 0
  num_train_steps: 0.5e+5
  
model:
  channels: [8, 32, 64, 128, 256, 512, 512, 1024, 1024]
  factors: [1, 4, 4, 4, 2, 2, 2, 2, 2]
  layers: [1, 2, 2, 2, 2, 2, 2, 4, 4]
  attentions: [0, 0, 0, 0, 0, 1, 1, 1, 1]
  cross_attentions: [0, 0, 0, 0, 0, 1, 1, 1, 1]
  attention_heads: 12
  attention_features: 64
  use_additional_time_conditioning: false
  use_initial_image: false
  use_embedding_cfg: true
  embedding_max_length: 64
  embedding_features: 512
  text_emb_channels: 192
  max_wav_len: 98304
  model_type: ConditionalDiffusionPhonemeToWav

loss:
  use_l1: true
  l1_weight: 1.0
  use_l2: true
  l2_weight: 1.0
  use_mrstft: true
  mrstft_weight: 0.5
